# model-optimizer

## 模型推理性能优化

我们支持客户在线/离线业务，实现模型目标的达成。包括降低时延，提升吞吐，优化系统资源利用等目的。我们优化的模型包括

### DL 模型

- Resnet
- SwinTransformer
- Vit
- Bert
- Siglip
- Clip

### LLM 类

LLM 类模型，根据应用场景以及 baseline 情况，我们通过模型适配、多样性部署、性能优化等工作，以实现用户期望目标为目的，
结合最新的研究成功，实现模型的高效推理， 为客户节约成本 50%～95% 。

- Vicuna 13B
- Llama 3.1
- Qwen 72B
- MiniCPMV 2.6
- Llava 优化 Llava-OneVision Llava-interleave 等模型推理性能, 在 LMDeploy/TensorRT-LLM 的基础上，离线吞吐提升 2 倍以上

### Custom VLM

- 支持自研模型的推理优化，分布式部署等。
- 支持 NVIDIA GPU
- 支持华为 Ascend GPU 等国产生态的适配与优化

## 项目合作

模型推理优化，联系 deepindeed2022@gmail.com，来信可以附带以下信息再好不过了。

- 模型地址或者模型结构描述
- 目标硬件
- 期望